{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "- ✅ Outliers extremos en un 3% de los datos (valores multiplicados por 5-10x).\n",
    "- ✅ Valores claramente incorrectos en columnas clave (ej. OxygenSaturation con valores de 200%).\n",
    "- ✅ Errores de digitación en variables categóricas (Present → Presnt, Epithelial → Epthlial).\n",
    "- ✅ Intercambio de valores entre columnas (CellSize ↔ MitosisRate para simular errores de ingreso de datos).\n",
    "- ✅ Más valores nulos (10%) en distintas features.\n",
    "- ✅ Datos duplicados con pequeñas variaciones para simular mediciones imprecisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics by Rebalancing Method:\n",
      "                      Accuracy  Precision  Recall  F1-Score  AUC-ROC  AUC-PR\n",
      "No Rebalancing           0.758      0.667   0.066     0.119    0.768   0.514\n",
      "Random Undersampling     0.656      0.386   0.639     0.481    0.695   0.463\n",
      "Random Oversampling      0.725      0.469   0.738     0.573    0.778   0.517\n",
      "SMOTE                    0.738      0.484   0.738     0.584    0.797   0.552\n",
      "Cost Re-weighting        0.725      0.468   0.721     0.568    0.782   0.530\n"
     ]
    }
   ],
   "source": [
    "# Requiere: pip install imbalanced-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix, roc_curve, precision_recall_curve\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# --- Preprocesamiento ---\n",
    "\n",
    "# Cargar el dataset\n",
    "df_dev = pd.read_csv(\"data/cell_diagnosis_dev_imbalanced.csv\")\n",
    "df_test = pd.read_csv(\"data/cell_diagnosis_test_imbalanced.csv\")\n",
    "\n",
    "# Separar features y target\n",
    "X = df_dev.drop(columns=[\"Diagnosis\"])\n",
    "y = df_dev[\"Diagnosis\"]\n",
    "\n",
    "# Split en train y val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Imputación numérica\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train_cont = X_train.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "X_val_cont = X_val.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "X_train_cont_imputed = pd.DataFrame(imputer.fit_transform(X_train_cont), columns=X_train_cont.columns)\n",
    "X_val_cont_imputed = pd.DataFrame(imputer.transform(X_val_cont), columns=X_val_cont.columns)\n",
    "\n",
    "# Codificación categórica\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "X_train_cat = X_train.select_dtypes(include=[\"object\"]).fillna(\"Missing\")\n",
    "X_val_cat = X_val.select_dtypes(include=[\"object\"]).fillna(\"Missing\")\n",
    "X_train_cat_encoded = pd.DataFrame(encoder.fit_transform(X_train_cat),\n",
    "                                   columns=encoder.get_feature_names_out(X_train_cat.columns))\n",
    "X_val_cat_encoded = pd.DataFrame(encoder.transform(X_val_cat),\n",
    "                                 columns=encoder.get_feature_names_out(X_val_cat.columns))\n",
    "\n",
    "# Concatenar\n",
    "X_train_processed = pd.concat([X_train_cont_imputed, X_train_cat_encoded], axis=1)\n",
    "X_val_processed = pd.concat([X_val_cont_imputed, X_val_cat_encoded], axis=1)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
    "X_val_scaled = scaler.transform(X_val_processed)\n",
    "\n",
    "# --- Función de entrenamiento y evaluación ---\n",
    "results = {}\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_val_scaled, y_val, method_name, class_weight=None):\n",
    "    model = LogisticRegression(penalty='l2', solver='liblinear', random_state=42, class_weight=class_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "    results[method_name] = {\n",
    "        \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "        \"Precision\": precision_score(y_val, y_pred),\n",
    "        \"Recall\": recall_score(y_val, y_pred),\n",
    "        \"F1-Score\": f1_score(y_val, y_pred),\n",
    "        \"AUC-ROC\": roc_auc_score(y_val, y_proba),\n",
    "        \"AUC-PR\": average_precision_score(y_val, y_proba)\n",
    "    }\n",
    "\n",
    "# --- Aplicar distintas técnicas ---\n",
    "\n",
    "# 1. Sin re-balanceo\n",
    "train_and_evaluate(X_train_scaled, y_train, X_val_scaled, y_val, \"No Rebalancing\")\n",
    "\n",
    "# 2. Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_rus, y_rus, X_val_scaled, y_val, \"Random Undersampling\")\n",
    "\n",
    "# 3. Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_ros, y_ros, X_val_scaled, y_val, \"Random Oversampling\")\n",
    "\n",
    "# 4. SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_smote, y_smote, X_val_scaled, y_val, \"SMOTE\")\n",
    "\n",
    "# 5. Cost-sensitive learning\n",
    "train_and_evaluate(X_train_scaled, y_train, X_val_scaled, y_val, \"Cost Re-weighting\", class_weight=\"balanced\")\n",
    "\n",
    "# --- Mostrar resultados ---\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"Validation Metrics by Rebalancing Method:\")\n",
    "print(df_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Con Feature Engineering y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "                      Accuracy  Precision  Recall  F1-Score  AUC-ROC  AUC-PR\n",
      "No Rebalancing           0.946      0.910   0.976     0.942    0.968   0.931\n",
      "Random Undersampling     0.953      0.911   0.992     0.950    0.969   0.934\n",
      "Random Oversampling      0.953      0.911   0.992     0.950    0.969   0.935\n",
      "SMOTE                    0.949      0.910   0.984     0.946    0.967   0.931\n",
      "Cost Re-weighting        0.949      0.910   0.984     0.946    0.968   0.933\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Load and clean data ---\n",
    "df_dev = pd.read_csv(\"data/cell_diagnosis_dev.csv\")\n",
    "df_test = pd.read_csv(\"data/cell_diagnosis_test.csv\")\n",
    "\n",
    "# Remove outliers using IQR\n",
    "def remove_outliers(df, columns):\n",
    "    Q1 = df[columns].quantile(0.25)\n",
    "    Q3 = df[columns].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = ~((df[columns] < (Q1 - 1.5 * IQR)) | (df[columns] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    return df[mask]\n",
    "\n",
    "num_columns = df_dev.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "df_dev = remove_outliers(df_dev, num_columns)\n",
    "\n",
    "# Correct invalid values\n",
    "df_dev['OxygenSaturation'] = df_dev['OxygenSaturation'].clip(50, 100)\n",
    "df_dev['MitosisRate'] = df_dev['MitosisRate'].clip(0, 20)\n",
    "df_dev['CellSize'] = df_dev['CellSize'].clip(5, 200)\n",
    "\n",
    "# Unify categorical values\n",
    "category_corrections = {\n",
    "    'CellType': {'Epthlial': 'Epithelial', 'Mesnchymal': 'Mesenchymal', '???': 'Unknown'},\n",
    "    'GeneticMutation': {'Presnt': 'Present', 'Absnt': 'Absent', 'Error': 'Unknown'}\n",
    "}\n",
    "for col, mapping in category_corrections.items():\n",
    "    if col in df_dev.columns:\n",
    "        df_dev[col] = df_dev[col].replace(mapping)\n",
    "    if col in df_test.columns:\n",
    "        df_test[col] = df_test[col].replace(mapping)\n",
    "\n",
    "# --- Split into train and val ---\n",
    "X = df_dev.drop(columns=['Diagnosis'])\n",
    "y = df_dev['Diagnosis']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# --- Preprocessing pipeline ---\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def preprocess(X_train, X_val):\n",
    "    X_train_num = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "    X_val_num = X_val.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "    X_train_num_imputed = pd.DataFrame(imputer.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num_imputed = pd.DataFrame(imputer.transform(X_val_num), columns=X_val_num.columns)\n",
    "\n",
    "    X_train_cat = X_train.select_dtypes(include=['object']).fillna(\"Missing\")\n",
    "    X_val_cat = X_val.select_dtypes(include=['object']).fillna(\"Missing\")\n",
    "\n",
    "    X_train_cat_enc = pd.DataFrame(encoder.fit_transform(X_train_cat), columns=encoder.get_feature_names_out(X_train_cat.columns))\n",
    "    X_val_cat_enc = pd.DataFrame(encoder.transform(X_val_cat), columns=encoder.get_feature_names_out(X_val_cat.columns))\n",
    "\n",
    "    X_train_final = pd.concat([X_train_num_imputed, X_train_cat_enc], axis=1)\n",
    "    X_val_final = pd.concat([X_val_num_imputed, X_val_cat_enc], axis=1)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    X_val_scaled = scaler.transform(X_val_final)\n",
    "\n",
    "    return X_train_scaled, X_val_scaled\n",
    "\n",
    "X_train_scaled, X_val_scaled = preprocess(X_train, X_val)\n",
    "\n",
    "# --- Entrenamiento y evaluación ---\n",
    "results = {}\n",
    "\n",
    "def train_and_evaluate(X_tr, y_tr, name, class_weight=None):\n",
    "    model = LogisticRegression(penalty='l2', solver='liblinear', class_weight=class_weight, random_state=42)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_val, y_pred),\n",
    "        \"Precision\": precision_score(y_val, y_pred),\n",
    "        \"Recall\": recall_score(y_val, y_pred),\n",
    "        \"F1-Score\": f1_score(y_val, y_pred),\n",
    "        \"AUC-ROC\": roc_auc_score(y_val, y_proba),\n",
    "        \"AUC-PR\": average_precision_score(y_val, y_proba)\n",
    "    }\n",
    "\n",
    "# No rebalancing\n",
    "train_and_evaluate(X_train_scaled, y_train, \"No Rebalancing\")\n",
    "\n",
    "# Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_rus, y_rus, \"Random Undersampling\")\n",
    "\n",
    "# Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_ros, y_ros, \"Random Oversampling\")\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "train_and_evaluate(X_smote, y_smote, \"SMOTE\")\n",
    "\n",
    "# Cost re-weighting\n",
    "train_and_evaluate(X_train_scaled, y_train, \"Cost Re-weighting\", class_weight='balanced')\n",
    "\n",
    "# --- Resultados ---\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nValidation Results:\")\n",
    "print(df_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results:\n",
      "                      Accuracy  Precision  Recall  F1-Score  AUC-ROC  AUC-PR\n",
      "No Rebalancing           0.897      0.872   0.904     0.888    0.832   0.742\n",
      "Random Undersampling     0.886      0.869   0.880     0.874    0.814   0.723\n",
      "Random Oversampling      0.897      0.872   0.904     0.888    0.833   0.744\n",
      "SMOTE                    0.897      0.872   0.904     0.888    0.833   0.739\n",
      "Cost Re-weighting        0.897      0.872   0.904     0.888    0.832   0.742\n"
     ]
    }
   ],
   "source": [
    "# --- Preprocesamiento del test set ---\n",
    "X_test = df_test.drop(columns=[\"Diagnosis\"])\n",
    "y_test = df_test[\"Diagnosis\"]\n",
    "\n",
    "X_test_num = X_test.select_dtypes(include=['float64', 'int64'])\n",
    "X_test_cat = X_test.select_dtypes(include=['object']).fillna(\"Missing\")\n",
    "\n",
    "X_test_num_imputed = pd.DataFrame(imputer.transform(X_test_num), columns=X_test_num.columns)\n",
    "X_test_cat_encoded = pd.DataFrame(encoder.transform(X_test_cat),\n",
    "                                  columns=encoder.get_feature_names_out(X_test_cat.columns))\n",
    "\n",
    "X_test_processed = pd.concat([X_test_num_imputed, X_test_cat_encoded], axis=1)\n",
    "X_test_scaled = scaler.transform(X_test_processed)\n",
    "\n",
    "# --- Función de evaluación en test ---\n",
    "test_results = {}\n",
    "\n",
    "def evaluate_on_test(X_train_bal, y_train_bal, method_name, class_weight=None):\n",
    "    model = LogisticRegression(penalty='l2', solver='liblinear', class_weight=class_weight, random_state=42)\n",
    "    model.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    test_results[method_name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred),\n",
    "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
    "        \"AUC-PR\": average_precision_score(y_test, y_proba)\n",
    "    }\n",
    "\n",
    "# 1. No rebalancing\n",
    "evaluate_on_test(X_train_scaled, y_train, \"No Rebalancing\")\n",
    "\n",
    "# 2. Random Undersampling\n",
    "evaluate_on_test(X_rus, y_rus, \"Random Undersampling\")\n",
    "\n",
    "# 3. Random Oversampling\n",
    "evaluate_on_test(X_ros, y_ros, \"Random Oversampling\")\n",
    "\n",
    "# 4. SMOTE\n",
    "evaluate_on_test(X_smote, y_smote, \"SMOTE\")\n",
    "\n",
    "# 5. Cost Re-weighting\n",
    "evaluate_on_test(X_train_scaled, y_train, \"Cost Re-weighting\", class_weight='balanced')\n",
    "\n",
    "# --- Mostrar resultados ---\n",
    "df_test_results = pd.DataFrame(test_results).T\n",
    "print(\"Test Set Evaluation Results:\")\n",
    "print(df_test_results.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
