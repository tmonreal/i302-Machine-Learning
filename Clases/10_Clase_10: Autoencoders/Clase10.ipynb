{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77dda79",
   "metadata": {},
   "source": [
    "Variational Autoencoder (VAE) es un modelo generativo.\n",
    "- Esto significa que estamos intentando modelar como **generamos** los datos (es decir, aprender la distribuci√≥n de los mismos), no solo como mapeamos $x \\rightarrow y$, como haciamos en aprendizaje supervisado.\n",
    "- Entonces, nos preguntamos: _¬øComo pueden haberse generado estos datos $x$ en la vida real?_\n",
    "- Respuesta: De una variable latente $z$ que captura la estructura no observada, y de un proceso condicional $x‚àºp_Œ∏(x‚à£z)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f9fd3",
   "metadata": {},
   "source": [
    "**Modelo de Variable Latente**\n",
    "\n",
    "Forma probabilistica est√°ndar de cualquier modelo probabilistico de variable latente:\n",
    "\n",
    "$$ p_Œ∏(z,x) = p_Œ∏(z)p_Œ∏(x|z)$$\n",
    "\n",
    "Donde:\n",
    "- $z$: variable latente (factores no observados).\n",
    "    - Ejemplo: para una oraci√≥n podr√≠a ser: tematica (deportes, politica, ...), sentimiento (positivo, neutral, negativo), estilo (formal, casual), etc\n",
    "\n",
    "- $p_Œ∏(z)$: prior sobre las variables latentes (en general, distribuci√≥n normal est√°ndar)\n",
    " \n",
    "- $p_Œ∏(x|z)$: decoder que mapea del espacio latente al espacio de datos\n",
    "\n",
    "- $p_Œ∏(z,x)$: probabilidad conjunta sobre las variables latentes y observadas.\n",
    "\n",
    "¬øPor qu√© empezamos modelando desde ac√°?\n",
    "- VAE quiere modelar $p(x)$ (la distribuci√≥n de los datos) usando variables latentes. Esto quiere decir:\n",
    "\n",
    "$$ p_Œ∏(x) = \\int p_Œ∏(z,x)dz = \\int p_Œ∏(z)p_Œ∏(x|z)dz $$\n",
    "\n",
    "- Es decir:\n",
    "1. Primero gener√°s un latente $z$ desde una distribuci√≥n conocida, como $N(0,I)$\n",
    "2. Luego gener√°s un dato $x$ a partir de ese $z$.\n",
    "\n",
    "üëâ Pero en la realidad solo observ√°s $x$, no $z$. Entonces, si quer√©s saber qu√© tan probable es un dato $x$ seg√∫n tu modelo, ten√©s que sumar (integrar) sobre todos los posibles valores que pudo haber tenido $z$.\n",
    "\n",
    "- Pero... esa integral es intractable, por eso usamos una aproximaci√≥n: el ELBO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e3d3f",
   "metadata": {},
   "source": [
    "Entonces volvamos al inicio:\n",
    "\n",
    "$$ p_Œ∏(z,x) = p_Œ∏(z)p_Œ∏(x|z) $$\n",
    "\n",
    "- Dijimos que $p_Œ∏(z)$ suele ser una Gaussiana.\n",
    "- $p_Œ∏(x|z)$ (_‚ÄúDado un valor z en el espacio latente, ¬øc√≥mo se ve un dato x?‚Äù_) suele ser el producto de distribuciones de la familia exponencial.\n",
    "    - _¬øPorque producto de distribuciones?_ Porque normalmente suponemos que las componentes de x son independientes entre s√≠ dado z. Entonces podemos escribir: $p_Œ∏(x|z) = \\prod_{i=1}^D p_Œ∏(x_i|z)$. Simplifica el calculo\n",
    "    - _¬øPorque esas distribuciones?_\n",
    "        - Si los datos son binarios (ej: pixel blanco o negro) usamos $x_i ‚àà {0,1} ‚áí p_Œ∏(x_i‚à£z)=Bernoulli(Œº_i(z))$. Entonces: $p_Œ∏(x|z) = \\prod_{i=1}^D Bernoulli(x_i; \\mu_i(z))$. Entonces la red nos da los $Œº_i(z) ‚àà(0,1)$, o sea, las probabilidades de que cada p√≠xel sea 1.\n",
    "        \n",
    "        - Si los datos son continuos (como im√°genes en escala de grises normalizadas o audio): $x_i ‚àà \\R ‚áí p_Œ∏(x_i‚à£z)=\\mathcal{N}(x_i;Œº_i(z), \\sigma¬≤)$. En general se asume varianza fija: $p_Œ∏(x|z) = \\prod_{i=1}^D \\mathcal{N}(x_i;Œº_i(z), \\sigma¬≤)$. Entonces la red nos devuelve los $Œº_i(z)$ y opcionalmente los $\\sigma_i¬≤$\n",
    "\n",
    "    - _¬øPorque tiene sentido hacerlo asi?_\n",
    "        - Desde el punto de vista probabil√≠stico, necesitamos una funci√≥n de densidad para evaluar la probabilidad del dato x dado un z.\n",
    "        - Desde el punto de vista computacional, multiplicar distribuciones independientes simplifica el logaritmo.\n",
    "        - Desde el punto de vista del aprendizaje, nos permite definir la funci√≥n de p√©rdida (log-likelihood) y derivarla para actualizar los pesos de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87359a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
