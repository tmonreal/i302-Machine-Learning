{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin tecnicas de remuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_train2.csv\")\n",
    "valid_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_valid2.csv\")\n",
    "test_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_size = train_data.shape[0] + valid_data.shape[0] + test_data.shape[0]\n",
    "combined_df = pd.concat([train_data, valid_data, test_data], ignore_index=True)\n",
    "unique_size = combined_df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No repeated samples found across all datasets.\n"
     ]
    }
   ],
   "source": [
    "if combined_size == unique_size:\n",
    "    print(\"No repeated samples found across all datasets.\")\n",
    "else:\n",
    "    print(f\"There are {combined_size - unique_size} repeated samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets successfully split and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Download the credit card fraud dataset\n",
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "\n",
    "# Define folder paths for saving datasets (replace with your actual paths)\n",
    "train_folder = \"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/train\"  # Modify as needed\n",
    "valid_folder = \"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/valid\"  # Modify as needed\n",
    "test_folder = \"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/test\"  # Modify as needed\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(valid_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# Split the dataset (consider cleaning before splitting, if applicable)\n",
    "train_df, test_df = train_test_split(raw_df, test_size=0.2, random_state=42)  # Set random state for reproducibility\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)  # Maintain the same random state\n",
    "\n",
    "# Save the datasets as CSV files\n",
    "train_df.to_csv(os.path.join(train_folder, 'credit_card_train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(valid_folder, 'credit_card_valid.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(test_folder, 'credit_card_test.csv'), index=False)\n",
    "\n",
    "print(\"Datasets successfully split and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average class probability in training set:   0.0018\n",
      "Average class probability in validation set: 0.0014\n",
      "Average class probability in test set:       0.0017\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas sobre el conjunto de validación:\n",
      "Matriz de Confusión:\n",
      "[[45505     0]\n",
      " [   16    48]]\n",
      "Accuracy: 0.9996488841098115\n",
      "Precision: 1.0\n",
      "Recall: 0.75\n",
      "AUC-ROC: 0.875\n",
      "AUPRC: 0.8751755579450943\n",
      "\n",
      "Métricas sobre el conjunto de prueba:\n",
      "Matriz de Confusión:\n",
      "[[56861     3]\n",
      " [   22    76]]\n",
      "Accuracy: 0.9995611109160493\n",
      "Precision: [0.00172045 0.96202532 1.        ]\n",
      "Recall: [1.        0.7755102 0.       ]\n",
      "AUC-ROC: 0.8877287233126226\n",
      "AUPRC: 0.8689608714656027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# Leer los archivos CSV\n",
    "train_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/train/credit_card_train.csv\")\n",
    "valid_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/valid/credit_card_valid.csv\")\n",
    "test_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/test/credit_card_test.csv\")\n",
    "\n",
    "# Separar las características (features) y las etiquetas (labels)\n",
    "X_train = train_data.drop(\"Class\", axis=1)\n",
    "y_train = train_data[\"Class\"]\n",
    "X_valid = valid_data.drop(\"Class\", axis=1)\n",
    "y_valid = valid_data[\"Class\"]\n",
    "X_test = test_data.drop(\"Class\", axis=1)\n",
    "y_test = test_data[\"Class\"]\n",
    "\n",
    "# Entrenar el modelo de Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=20,\n",
    "                                       criterion='entropy', \n",
    "                                       random_state=0,\n",
    "                                       max_depth=10)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predecir sobre el conjunto de validación\n",
    "y_valid_pred = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Calcular las métricas sobre el conjunto de validación\n",
    "conf_matrix_valid = confusion_matrix(y_valid, y_valid_pred)\n",
    "accuracy_valid = accuracy_score(y_valid, y_valid_pred)\n",
    "precision_valid = precision_score(y_valid, y_valid_pred)\n",
    "recall_valid = recall_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calcular curva ROC y AUC-ROC sobre el conjunto de validación\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_valid_pred)\n",
    "auc_roc_valid = auc(fpr, tpr)\n",
    "\n",
    "# Calcular curva PRC y AUPRC sobre el conjunto de validación\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_valid_pred)\n",
    "auprc_valid = auc(recall, precision)\n",
    "\n",
    "# Reportar las métricas sobre el conjunto de validación\n",
    "print(\"Métricas sobre el conjunto de validación:\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix_valid)\n",
    "print(\"Accuracy:\", accuracy_valid)\n",
    "print(\"Precision:\", precision_valid)\n",
    "print(\"Recall:\", recall_valid)\n",
    "print(\"AUC-ROC:\", auc_roc_valid)\n",
    "print(\"AUPRC:\", auprc_valid)\n",
    "\n",
    "# Predecir sobre el conjunto de prueba\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calcular las métricas sobre el conjunto de prueba\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# Calcular curva ROC y AUC-ROC sobre el conjunto de prueba\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "auc_roc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Calcular curva PRC y AUPRC sobre el conjunto de prueba\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_pred)\n",
    "auprc_test = auc(recall_test, precision_test)\n",
    "\n",
    "# Reportar las métricas sobre el conjunto de prueba\n",
    "print(\"\\nMétricas sobre el conjunto de prueba:\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix_test)\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"AUC-ROC:\", auc_roc_test)\n",
    "print(\"AUPRC:\", auprc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando implementacion from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-84cb07e2f548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                        max_depth=10)\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Predecir sobre el conjunto de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML/Clases/Clase 3/i302/RF.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0my_bootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbootstrap_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML/Clases/Clase 3/i302/RF.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grow_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML/Clases/Clase 3/i302/RF.py\u001b[0m in \u001b[0;36m_grow_tree\u001b[0;34m(self, X, y, depth)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mindices_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ML/Clases/Clase 3/i302/RF.py\u001b[0m in \u001b[0;36m_best_split\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mgini_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_left\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mgini_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_right\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mgini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgini_left\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgini_right\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from RF import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "\n",
    "# Leer los archivos CSV\n",
    "train_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_train.csv\")\n",
    "valid_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_valid.csv\")\n",
    "test_data = pd.read_csv(\"/home/linar/Desktop/ML/Clases/Clase 3/i302/TP3/Data/2 - Credit Card Fraud/credit_card_test.csv\")\n",
    "\n",
    "# Separar las características (features) y las etiquetas (labels)\n",
    "X_train = train_data.drop(\"Class\", axis=1)\n",
    "y_train = train_data[\"Class\"]\n",
    "X_valid = valid_data.drop(\"Class\", axis=1)\n",
    "y_valid = valid_data[\"Class\"]\n",
    "X_test = test_data.drop(\"Class\", axis=1)\n",
    "y_test = test_data[\"Class\"]\n",
    "\n",
    "# Entrenar el modelo de Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_trees=20,\n",
    "                                       max_depth=10)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predecir sobre el conjunto de validación\n",
    "y_valid_pred = rf_classifier.predict(X_valid)\n",
    "\n",
    "# Calcular las métricas sobre el conjunto de validación\n",
    "conf_matrix_valid = confusion_matrix(y_valid, y_valid_pred)\n",
    "accuracy_valid = accuracy_score(y_valid, y_valid_pred)\n",
    "precision_valid = precision_score(y_valid, y_valid_pred)\n",
    "recall_valid = recall_score(y_valid, y_valid_pred)\n",
    "\n",
    "# Calcular curva ROC y AUC-ROC sobre el conjunto de validación\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_valid_pred)\n",
    "auc_roc_valid = auc(fpr, tpr)\n",
    "\n",
    "# Calcular curva PRC y AUPRC sobre el conjunto de validación\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_valid_pred)\n",
    "auprc_valid = auc(recall, precision)\n",
    "\n",
    "# Reportar las métricas sobre el conjunto de validación\n",
    "print(\"Métricas sobre el conjunto de validación:\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix_valid)\n",
    "print(\"Accuracy:\", accuracy_valid)\n",
    "print(\"Precision:\", precision_valid)\n",
    "print(\"Recall:\", recall_valid)\n",
    "print(\"AUC-ROC:\", auc_roc_valid)\n",
    "print(\"AUPRC:\", auprc_valid)\n",
    "\n",
    "# Predecir sobre el conjunto de prueba\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calcular las métricas sobre el conjunto de prueba\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "\n",
    "# Calcular curva ROC y AUC-ROC sobre el conjunto de prueba\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n",
    "auc_roc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Calcular curva PRC y AUPRC sobre el conjunto de prueba\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_pred)\n",
    "auprc_test = auc(recall_test, precision_test)\n",
    "\n",
    "# Reportar las métricas sobre el conjunto de prueba\n",
    "print(\"\\nMétricas sobre el conjunto de prueba:\")\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(conf_matrix_test)\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"AUC-ROC:\", auc_roc_test)\n",
    "print(\"AUPRC:\", auprc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i302",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
